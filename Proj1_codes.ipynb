{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The python codes for Project1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('./listings.csv')\n",
    "df.head()\n",
    "\n",
    "#clean up some data, remove columns will all missing data or data input without id number\n",
    "nd1 = df.dropna(how='all', axis=1)\n",
    "nd1 = nd1.dropna(subset =['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First got the count of listings for different neighbourhood\n",
    "\n",
    "num_list = nd1.groupby(['host_neighbourhood'])['id'].count()\n",
    "main_list= num_list[num_list>50]\n",
    "main_list = main_list.sort_values(ascending = False)\n",
    "main_list.plot(kind='bar', stacked=True, figsize=[10,6], colormap='winter',title='Boston Neighbourhoods Providing Most Airbnb Accomodations') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we try to get the information of price and review score for different neibourhood. To make\n",
    "the comparison more meaningful, we split the listing to 1 bed, 2 beds, 3 beds and 4+ beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the 'price' of the dataset is in the format of currency, convert it to numeric format\n",
    "\n",
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_ALL,'')\n",
    "#print(df['price'])\n",
    "\n",
    "aa = nd1['price']\n",
    "bb = aa\n",
    "\n",
    "#print(aa[aa.isnull()].count())\n",
    "\n",
    "for i in range(len(aa)):\n",
    "    bb[i] = locale.atof(aa[i].strip(\"$\"))\n",
    "\n",
    "nd1['price'] = pd.to_numeric(bb)\n",
    "#print(bb)\n",
    "print(nd1['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now group price and review scores by bed numbers and neighbourhoods\n",
    "\n",
    "#aggregate bed >3 together\n",
    "nd1['beds'].loc[nd1['beds']>3]=8.0\n",
    "\n",
    "\n",
    "dprice=nd1.groupby(['beds','host_neighbourhood'])['price','review_scores_rating'].describe().reset_index()\n",
    "\n",
    "dprice.set_index('host_neighbourhood')\n",
    "\n",
    "print(dprice.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract information for 1 bed, 2 beds, 3 beds and 4+ beds\n",
    "\n",
    "#Got one bed with count >30\n",
    "cond1 = dprice['beds']>0\n",
    "cond2 = dprice['beds'] <1.5\n",
    "cond3 = dprice['price']['count'] >30\n",
    "cond = cond1 & cond2 &cond3\n",
    "#print(cond)\n",
    "nprice1 = dprice[cond]\n",
    "#nprice1 = price[price['beds']>0 and price['beds'] <1.5]\n",
    "#print(nprice1)\n",
    "\n",
    "#Got two bed with count >30\n",
    "cond1 = dprice['beds'] >1.5\n",
    "cond2 = dprice['beds'] <2.5\n",
    "cond3 = dprice['price']['count'] >20\n",
    "cond = cond1 & cond2 &cond3\n",
    "#print(cond)\n",
    "nprice2 = dprice[cond]\n",
    "#nprice1 = price[price['beds']>0 and price['beds'] <1.5]\n",
    "#print(nprice2)\n",
    "\n",
    "#Got three bed with count >10\n",
    "cond1 = dprice['beds'] >2.5\n",
    "cond2 = dprice['beds'] <3.5\n",
    "cond3 = dprice['price']['count'] >10\n",
    "cond = cond1 & cond2 &cond3\n",
    "#print(cond)\n",
    "nprice3 = dprice[cond]\n",
    "#nprice1 = price[price['beds']>0 and price['beds'] <1.5]\n",
    "#print(nprice3)\n",
    "\n",
    "#Got 4+ bed with count >5\n",
    "cond1 = dprice['beds'] >4\n",
    "#cond2 = dprice['beds'] <3.5\n",
    "cond3 = dprice['price']['count'] >5\n",
    "cond = cond1 & cond3\n",
    "#print(cond)\n",
    "nprice4 = dprice[cond]\n",
    "#nprice1 = price[price['beds']>0 and price['beds'] <1.5]\n",
    "#print(nprice4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now plot the histogram for each catagory\n",
    "\n",
    "plt.figure(figsize=[12,6])\n",
    "plt.subplot(1,2,1)\n",
    "pos = np.arange(nprice1.shape[0])\n",
    "plt.bar(pos-0.2, nprice1['review_scores_rating']['mean'], align='center',color='g',width=0.35)\n",
    "plt.bar(pos+0.2, nprice1['price']['mean'], align='center',color='r',width=0.35)\n",
    "#ptick = pos\n",
    "#for i in range(len(nprice1['host_neighbourhood'])):\n",
    "#    ptick[i] = pos[i] -0.5*len(list(nprice1['host_neighbourhood'])[i])\n",
    "\n",
    "plt.xticks(pos, nprice1['host_neighbourhood'],rotation=80)\n",
    "plt.ylabel('Price')\n",
    "plt.title('The price and review rating of 1 bed airbnb \\nin Boston', alpha=0.8)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "pos = np.arange(nprice2.shape[0])\n",
    "plt.bar(pos-0.2, nprice2['review_scores_rating']['mean'], align='center',color='g',width=0.35)\n",
    "plt.bar(pos+0.2, nprice2['price']['mean'], align='center',color='r',width=0.35)\n",
    "plt.xticks(pos, nprice2['host_neighbourhood'],rotation=80)\n",
    "plt.ylabel('Price')\n",
    "plt.title('The price and rating of 2 beds airbnb \\nin Boston', alpha=0.8)\n",
    "\n",
    "plt.figure(figsize=[12,6])\n",
    "plt.subplot(1,2,1)\n",
    "pos = np.arange(nprice3.shape[0])\n",
    "plt.bar(pos-0.2, nprice3['review_scores_rating']['mean'], align='center',color='g',width=0.35)\n",
    "plt.bar(pos+0.2, nprice3['price']['mean'], align='center',color='r',width=0.35)\n",
    "plt.xticks(pos, nprice3['host_neighbourhood'],rotation=80)\n",
    "plt.ylabel('Price')\n",
    "plt.title('The price and rating of 3 beds airbnb \\nin Boston', alpha=0.8)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "pos = np.arange(nprice4.shape[0])\n",
    "plt.bar(pos-0.2, nprice4['review_scores_rating']['mean'], align='center',color='g',width=0.35)\n",
    "plt.bar(pos+0.2, nprice4['price']['mean'], align='center',color='r',width=0.35)\n",
    "plt.xticks(pos, nprice4['host_neighbourhood'],rotation=80)\n",
    "plt.ylabel('Price')\n",
    "plt.title('The price and rating of 4 or more bed airbnb \\nin Boston', alpha=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start to prepare data for the modeling\n",
    "\n",
    "def create_dummy_df(df, cat_cols, dummy_na):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics: \n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "        '''\n",
    "\n",
    "    df = pd.get_dummies(df, columns = cat_cols, prefix = cat_cols, prefix_sep = '_', drop_first= True, dummy_na = dummy_na)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def prep_data(df,resp, dummy_na):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe \n",
    "    resp - the response column name\n",
    "    \n",
    "    OUTPUT\n",
    "    X - A matrix holding all of the variables you want to consider when predicting the response\n",
    "    including dummy columns for all the categorical variables in X with the original columns dropped\n",
    "    y - the corresponding response vector\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #Drop all the rows with no response value\n",
    "    df = df.dropna(subset = [resp])\n",
    "    \n",
    "    #Drop those columns with all missing data\n",
    "    df = df.dropna(how ='all',axis=1)\n",
    "    \n",
    "    #seperate response vector and the prediction matrix\n",
    "    y = df[resp]\n",
    "    X = df.drop(columns = resp)\n",
    "    \n",
    "    #For each numeric variable in X, fill the column with the mean value of the column.\n",
    "    for col in X.columns:\n",
    "        if X[col].dtypes in ['int64',  'float64'] :\n",
    "            X[col] = X[col].fillna(X[col].mean())\n",
    "    \n",
    "    #Create dummy columns for all the categorical variables in X, drop the original columns\n",
    "    X_cat = X.select_dtypes(include = ['object']).copy()\n",
    "    X_cat_cols = X_cat.columns\n",
    "    \n",
    "    X = create_dummy_df(df, X_cat_cols, dummy_na)\n",
    "    #X = pd.get_dummies(X, columns = X_cat_cols, prefix = X_cat_cols, prefix_sep = '_', drop_first= True, dummy_na = False)\n",
    "    \n",
    "    #fill the NAN in X with mean of the columns\n",
    "    fill_by_mean = lambda col:col.fillna(col.mean())\n",
    "    X = X.apply(fill_by_mean, axis=0)\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "#Use the function to create X and y, if I drop those urls from the data, the test score is much better\n",
    "nd1 = nd1.drop(columns = ['listing_url','thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url'])\n",
    "X, y = prep_data(nd1,'review_scores_rating', dummy_na=False) \n",
    "#X, y = prep_data(nd1,'price', dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a linear model for the data and test the model\n",
    "\n",
    "def proj1_linear_mod(X, y, test_size=.3, rand_state=42):\n",
    "    '''\n",
    "    INPUT:\n",
    "    X - a dataframe holding all the variables of interest as predictor\n",
    "    y - a vector holding response variable \n",
    "    \n",
    "    test_size - a float between [0,1] about what proportion of data should be in the test dataset\n",
    "    rand_state - an int that is provided as the random state for splitting the data into training and test \n",
    "    \n",
    "    OUTPUT:\n",
    "    test_score - float - r2 score on the test data\n",
    "    train_score - float - r2 score on the test data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    '''\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = test_size, random_state = rand_state)\n",
    "    \n",
    "    lm_model = LinearRegression(normalize = True)\n",
    "    lm_model.fit(X_train,y_train)\n",
    "    \n",
    "    y_test_pred = lm_model.predict(X_test)\n",
    "    #print(y_test_pred)\n",
    "    \n",
    "    y_train_pred = lm_model.predict(X_train)\n",
    "    \n",
    "    test_score = r2_score(y_test, y_test_pred)\n",
    "    train_score = r2_score(y_train, y_train_pred)\n",
    "\n",
    "    return test_score, train_score, lm_model, X_train, X_test, y_train, y_test\n",
    "\n",
    "#test the result\n",
    "test_score, train_score, lm_model, X_train, X_test, y_train, y_test = proj1_linear_mod(X, y, test_size=.3, rand_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the impact of the coefficients\n",
    "\n",
    "def coef_weights(coefficients, X_train):\n",
    "    '''\n",
    "    INPUT:\n",
    "    coefficients - the coefficients of the linear model \n",
    "    X_train - the training data, so the column names can be used\n",
    "    OUTPUT:\n",
    "    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n",
    "    \n",
    "    Provides a dataframe that can be used to understand the most influential coefficients\n",
    "    in a linear model by providing the coefficient estimates along with the name of the \n",
    "    variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    coefs_df['coefs'] = lm_model.coef_\n",
    "    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    return coefs_df\n",
    "\n",
    "#Use the function\n",
    "coef_df = coef_weights(lm_model.coef_, X_train)\n",
    "\n",
    "#A quick look at the top results\n",
    "coef_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
